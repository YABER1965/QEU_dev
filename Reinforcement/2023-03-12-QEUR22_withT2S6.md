---
title: QEUR22_withT2S6:　閑話休題～Stable_Diffusionの画風について(その1)
date: 2023-03-12
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "REWARD", "強化学習"]
excerpt: T法(2)をテクノメトリックスとして使った強化学習
---

## QEUR22_withT2S6:　閑話休題～Stable_Diffusionの画風について(その1)

## ～　アートは「人」なり　～

### ・・・　やっぱ、SDこそが本題。これは閑話休題じゃないね（笑）　・・・

QEU:FOUNDER ： “さあて、Stable_Diffusionについてもうちょっと進めましょう。目標は、**「Everybody is Creative_Class」**だから・・・。”

![imageJRL2-7-1](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-1.jpg)

QEU:FOUNDER ： “今回は**「画風の研究」**です。なんとなく、「（高齢者による）**イノベーション**」っぽいでしょ（笑）？最もポピュラーなMODELの中を覗いてみましょう。”

![imageJRL2-7-2](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-2.jpg)

D先生 ： “いやいや、アートな雰囲気がイケています。あぁ・・・、いいなぁ・・・。コレの中には、J国の誇るアーティストは（入っているの）？”

QEU:FOUNDER ： “これが、ちょっとねえ・・・。”

![imageJRL2-7-3](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-3.jpg)

D先生 ： “あらあら・・・、ダメダメじゃないですか・・・。結局、この画像は何らかの方法でMODELから生成させた画像のようですね。”

QEU:FOUNDER ： “ただし、モデルは常に更新されているから、いまは少しは良くなっているかもしれないですよ。まあ、アニメを出力したいのであれば、アニメに特化しているモデルを使えばよろしい。極端に言えば、こんなモノ（↓）とか・・・。”

![imageJRL2-7-4](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-4.jpg)

D先生 ： “これは特化しすぎです（笑）。”

QEU:FOUNDER ： “この閑話休題シリーズでは、**画風を指定した画像を出力して**遊んでみましょう。小生の好みで、このアーティストを選びました。”

![imageJRL2-7-5](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-5.jpg)

D先生 ： “ああ・・・。いい雰囲気だ・・・。”

QEU:FOUNDER ： “それでは、プログラムと結果をドン！！これから、このプログラムが少しづつ改造されますが、これがベースになります。”

```python
# --- STABLE DIFFUSION <START> ---
import torch
from torch import autocast
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler
#from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler
import ipywidgets as widgets
from ipywidgets import interact

%cd ~/../notebooks

## Use the lists below to select our model type, image output resolution, and the computer number format for inference
device = 'cuda'
## We recommend either v1-5 (index 1) or v2 (index 2)
#model_id = ['hakurei/waifu-diffusion',"../datasets/stable-diffusion-diffusers/stable-diffusion-v1-5/",'../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/']
model_id = ['./model/vae/waifu-diffusion',"../datasets/stable-diffusion-diffusers/stable-diffusion-v1-5/",'../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/']

## We strongly recommend using the v1-5 and v1-4 models with size 512, and the v2 models with size 768.
size = [512, 768]
## If you are using a GPU with ~ 8 GBs of RAM, like the Free-GPU Notebooks, then use torch.float16
## otherwise, either selection works
dtype = [torch.float16, torch.float32]

# Set your values here - defaults are for v2, size 768 x 768 with FP16 computer number format
model_ = model_id[1]
size_ = size[0] 
precision = dtype[0]

# -----
# Depending on the selections made above, the type of model loaded will change using this short if/else statement
print(f'Now loading Stable Diffusion {model_} model ({precision})...')
scheduler = EulerDiscreteScheduler.from_pretrained('stabilityai/stable-diffusion-2', subfold-er="scheduler")
#scheduler = LMSDiscreteScheduler.from_pretrained('stabilityai/stable-diffusion-2', subfold-er="scheduler")
# -----
if precision == torch.float16:
    if model_ == '../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/':
        pipe = StableDiffusionPipeline.from_pretrained(model_, torch_dtype=torch.float16, revi-sion="fp16", scheduler = scheduler)
        pipe = pipe.to(device)
    else:
        pipe = StableDiffusionPipeline.from_pretrained(model_, torch_dtype=torch.float16, revi-sion="fp16")
        pipe = pipe.to(device)
else:
    if model_ == '../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/':
        pipe = StableDiffusionPipeline.from_pretrained(model_, scheduler = scheduler)
        pipe = pipe.to(device)
    else:
        pipe = StableDiffusionPipeline.from_pretrained(model_)
        pipe = pipe.to(device)
print('Model now loaded. Head to next cell to generate images.')


# -----
from PIL import Image
from datetime import datetime

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows*cols

    w, h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    grid_w, grid_h = grid.size
    
    for i, img in enumerate(imgs):
        grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

# -----
# parameter
rows = 2
cols = 3
model_name = "SDV14"
sample_num = rows*cols
lst = []
# -----
print(f'Generating samples from Stable Diffusion {model_} checkpoint ({precision})')
type_name = "Albert_Joseph_Moore"
prompt   = '(1girl:1.3),standing,beach,look at viewer,high quality,masterpiece,blue eye,twintail,in style of {}'.format(type_name)
n_prompt = "(low quality), BW, (bad anatomy:1.3), deformed, text"
# -----
generator = torch.Generator("cuda").manual_seed(0)  

# -----
for j in range(sample_num):
    a = pipe(prompt, negative_prompt=n_prompt, generator=generator, 
             guidance_scale=9.0,
             height = size_,
             width = size_,
             num_inference_steps=30)['images'][0]
    lst.append(a)
    display(a)

    #生成日時をファイル名にして保存
    date = datetime.now().strftime("%Y%m%d_%H%M%S")
    fig_imgname = './outputs/gen-image-{0}-{1}-p{2}.png'.format(date,model_name,j)
    print("Individual picture - {} is done".format(fig_imgname))
    a.save(fig_imgname)
```

QEU:FOUNDER ： “個人的には、この絵が一番好きです。”

![imageJRL2-7-6](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-6.jpg)

D先生 ： “SDは細かい描写が苦手なんですが、今回はうまく腕を組んでいますね。イイ絵です！”

QEU:FOUNDER ： “ちなみに、合計6枚を出力させています。その一覧を見てみましょう。”

![imageJRL2-7-7](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-7.jpg)

D先生 ： “フレームから外れているのが1枚ある以外は、全体的にかなりイイセンいっています。やはり、モデルがかなり改善されているんでしょうね。”

QEU:FOUNDER ： “今回の機能改善では、negative promptも入れていますからね。さあて、このプログラムを使って、同じプロンプトを使って画風を切り替えて遊ぶという趣向です。”

D先生  ： “いかにも**「アートという感じ」**でいいですね。”


## ～　まとめ　～

### ・・・　前回のつづきです　・・・

QEU:FOUNDER ： “**「見た目はよいが、実は中は・・・」**って、よくある話じゃない？”

[![MOVIE1](/2023-03-12-QEUR22_withT2S6/imageJRL2-7-8.jpg)](https://imaple8.co/play/266404-3-1.html "Please Click to view the movie")

C部長 : “それ、ウチ（会社）のことを言ってます？・・・それにしても、このドキュメンタリー(↑)の中の街頭インタビューに出てくるJ国の人たちに違和感があったなぁ・・・。どうして、そんなに「あの人」をかばうのだろうか・・・。”

QEU:FOUNDER ： “小生は、それどころか夜中に悪夢にうなされて、「うわぁ！！」って、飛び上がっちゃいました。”

C部長 : “へ？なんの夢を見たんですか？”

QEU:FOUNDER ： “夢の中での小生は大学生で、卒論を書いていました。（夢の中の小生は）卒論に行き詰まったのか、それとも（卒論に）興味がなかったのか、別の美術学校で「美術史」の授業にでていたんだ・・・。そして授業が終わって街に出たら・・・。”

C部長 : “街に出たら？”

QEU:FOUNDER ： “街を歩く見知らぬ数十人の人たちが、**「なぜ卒論をやらん」**って、カッターナイフを振り回してきたんです。”

C部長 : “うわぁ・・・、こわっ・・・。この件とFOUNDERの夢と何の関係が？”

QEU:FOUNDER ： “あの人は天才だよ。それによって社会に巨大な経済的なメリットをもたらしました。でもね、それと被害者の件は別じゃない？なぜ、**「沢山の少年たちがその天才のいけにえ」**にならんといかんの？”

C部長 : “**J国では、一度「金のなる木」が確立すると、社会にはそれを維持しようとする巨大な力がかかるんです**。ボクも、むしろ一般の人のインタビューを聞いて飛び上がらんばかりに驚きました。被害に遭った人が実は同様に天才であり、将来、彼を超える経済的なメリットをもたらす可能性を感じないのか・・・？”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

### オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」

### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

QEU:FOUNDER ： “**一旦、「立場」が確立すると物事の良し悪しは二の次です**。すでに確立したシステムの保存が絶対条件であり、個人はそれに服従するかどうか、システムから指示されたことをやるかどうかですので・・・。オッサン（↑）の頭の中は、まさしくJ国のお国柄の反映なんですよ。”

C部長 : “いやぁ・・・。いやなもの（動画）を見ちゃった・・・。少なく見ても、この報道を機会に海外の対J国のモノの見方は変わってくるでしょうね。”

[![MOVIE2](http://img.youtube.com/vi/_h9CSnzLRtY/0.jpg)](http://www.youtube.com/watch?v=_h9CSnzLRtY "本音の本音。我慢して笑顔を作るな！それが社会のイノベーションを進める。嫌な仕事なんてサボれ！安冨歩東大教授。")

QEU:FOUNDER ： “まあ、個人の素直な道徳観や好き嫌い、さらには美的感覚をより重視する時代がきたんでしょうね。そういう意味で、来るラウンド(ROUND2_3)のStable_Diffusionのプロジェクトは意味があると思います。”

