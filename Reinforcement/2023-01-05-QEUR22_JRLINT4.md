---
title: QEUR22_JRLINT4:　POMDPs.jlでSARSAやQ-Learningを・・・
date: 2023-01-05
tags: ["QEUシステム", "メトリックス", "Julia言語", "機械学習", "Flux", "ディープラーニング", "強化学習"]
excerpt: Julia言語を使った強化学習
---

## QEUR22_JRLINT4:　POMDPs.jlでSARSAやQ-Learningを・・・

## ～　POMDPｓの現在の欠点は「情報不足」か・・・　～


QEU:FOUNDER （設定65歳） ： “さあて、この番組はひきつづき「高齢者によるイノベーション」です。今回もひきつづきPOMDPs.jlを使ってみましょう。”

[![MOVIE1](http://img.youtube.com/vi/ITzRizRpHzI/0.jpg)](http://www.youtube.com/watch?v=ITzRizRpHzI "[05x13] SARSA and Q-learning Algorithms with POMDPs.jl | Julia Reinforcement Machine Learning")

QEU:FOUNDER ： “まずは、この参考動画では最も簡単な1次元メイズであるRandom Walkをやっています。”

![imageJRL1-5-1](/2023-01-05-QEUR22_JRLINT4/imageJRL1-5-1.jpg)

D先生 ： “これは、ReinforcementLearning.jlでやっていたものと同じですね。もっとも簡単な一次元メイズ（迷路）です。今回は、これの上で**SARSAとかQ-Learning**を使うんですよね。”

QEU:FOUNDER ： “そうです。それでは、コードと実行結果をドン。”

```julia
################################################################################
# ML > Reinforcement Learning > SARSA and Q-learning Algorithms
################################################################################
# load packages
using POMDPs, POMDPModelTools, QuickPOMDPs

# load solvers
using DiscreteValueIteration, TabularTDLearning

# load policy
using POMDPPolicies

# load standard library
using Random

# define State data type
struct State
    x::Int
end

# define Action data type (@enum from Julia Base.Enums)
@enum Action LEFT RIGHT

# define state space
null = State(-1)
S = [[State(x) for x = 1:7]..., null]

# define action space
A = [LEFT, RIGHT]

# define transition function
const MOVEMENTS = Dict(
    LEFT => State(-1),
    RIGHT => State(1)
)

Base.:+(s1::State, s2::State) = State(s1.x + s2.x)

# -----
function T(s::State, a::Action)
    # Deterministic() from POMDPModelTools.jl
    if R(s) != 0
        return Deterministic(null)
    end

    # initialize variables (index 1 is current state)
    len_a = length(A)
    next_states = Vector{State}(undef, len_a + 1)
    probabilities = zeros(len_a + 1)

    # enumerate() from Julia Base.Iterators
    for (index, a_prime) in enumerate(A)
        prob = (a_prime == a) ? 0.8 : 0.2
        dest = s + MOVEMENTS[a_prime]
        next_states[index + 1] = dest

        if 1 <= dest.x <= 7
            probabilities[index + 1] += prob
        end
    end

    # handle out-of-bounds transitions
    next_states[1] = s
    probabilities[1] = 1 - sum(probabilities)

    # SparseCat from POMDPModelTools.jl
    return SparseCat(next_states, probabilities)
end

# define reward function
function R(s, a = missing)
    if s == State(1)
        return -1
    elseif s == State(7)
        return 1
    end
    return 0
end

# set discount factor
gamma = 0.95

# prep mdp
termination(s::State) = s == null
abstract type GridWorld <: MDP{State, Action} end

################################################################################
# SARSA Algorithm
################################################################################
# define mdp using QuickPOMDPs.jl
s_mdp = QuickMDP(GridWorld,
    states = S,
    actions = A,
    transition = T,
    reward = R,
    discount = gamma,
    initialstate = S, # new line
    isterminal = termination
)

# select solver from TabularTDLearning.jl
# select policy from POMDPPolicies.jl
Random.seed!(1)
s_alpha = 0.95

# try 1000 times
s_n_episodes = 1000

s_solver = SARSASolver(
    n_episodes = s_n_episodes,
    learning_rate = s_alpha,
	eval_every=50, 
    exploration_policy = EpsGreedyPolicy(s_mdp, 0.2),
    verbose = true
)

# solve mdp
s_policy = solve(s_solver, s_mdp)

```

![imageJRL1-5-2](/2023-01-05-QEUR22_JRLINT4/imageJRL1-5-2.jpg)

```julia
# V-value calculation for SARSA
arr_value_s = []
for (i, s) in enumerate(S)
    val = maximum(s_policy.value_table[i, :])
    act = action(s_policy, s)
    push!(arr_value_s, val)
    println("VALUE:",val, "  ACTION:", act) 
end
println(arr_value_s)

```

![imageJRL1-5-3](/2023-01-05-QEUR22_JRLINT4/imageJRL1-5-3.jpg)

```julia
################################################################################
# Q-learning Algorithm
################################################################################
# define mdp using QuickPOMDPs.jl
q_mdp = QuickMDP(GridWorld,
    states = S,
    actions = A,
    transition = T,
    reward = R,
    discount = gamma,
    initialstate = S, # new line
    isterminal = termination
)

# select solver from TabularTDLearning.jl
# select policy from POMDPPolicies.jl
Random.seed!(1)
q_alpha = 0.95

# try 1000 times
q_n_episodes = 1000

q_solver = QLearningSolver(
    n_episodes = q_n_episodes,
    learning_rate = q_alpha,
    exploration_policy = EpsGreedyPolicy(q_mdp, 0.2),
    verbose = true
)

# solve mdp
q_policy = solve(q_solver, q_mdp)
```

![imageJRL1-5-4](/2023-01-05-QEUR22_JRLINT4/imageJRL1-5-4.jpg)

```julia
# V-value calculation for QLearning
arr_value_q = []
for (i, s) in enumerate(S)
    val = maximum(q_policy.value_table[i, :])
    act = action(q_policy, s)
    push!(arr_value_q, val)
    println("VALUE:",val, "  ACTION:", act) 
end
println(arr_value_q)
```

![imageJRL1-5-5](/2023-01-05-QEUR22_JRLINT4/imageJRL1-5-5.jpg)

```julia
# Plot the difference
using Plots
gr()

plot(arr_value_s[1:end-1], label="SARSA")
plot!(arr_value_q[1:end-1], label="QLearning")
```

![imageJRL1-5-6](/2023-01-05-QEUR22_JRLINT4/imageJRL1-5-6.jpg)

D先生 ： “今回はV値を調べたことが新しいですね。SARSAとQ-LearningではV値の傾向がこんなに違うんですね。”

QEU:FOUNDER ： “**「table_value」というプロパティ**を見つけたからね。・・・でも、これを見つけるのに本当に苦労したよ。POMDPs.jlのドキュメンテーションはReinforcementLearning.jlよりも遅れているように感じます。”

D先生 ： “これでは、POMDPs.jlでContinuous(ディープラーニング)は難しいですかね・・・。”

QEU:FOUNDER ： “彼らは(Continuousが)できるとはいっているんですが・・・。根気よく調査しながら、ドキュメントに出会えることを祈るだけです(笑)。”

D先生 ： “もういちど、ReinforcementLearning.jlにもどりましょうか・・・。”


## ～　まとめ　～

QEU:FOUNDER ： “ChatGPTについて、かなりわかりやすい動画がでましたよ。”

[![MOVIE2](http://img.youtube.com/vi/5hwgVD4B5og/0.jpg)](http://www.youtube.com/watch?v=5hwgVD4B5og "ChatGPT - Elon Musk 有關的 AI 聊天軟件 即將被 AI 淘汰的 5 種職業 (已經發生中)")

C部長 : “すいません。そもそも「言葉」がわからないんですが・・・。・・・でも、ものすごい可能性をもつ技術であることがわかりますね。”

QEU:FOUNDER ： “「こんな仕事がなくなる！？」とか言われていますが、まああと5年は気にすることはないと思いますよ。ただし、すぐにマニュアルやQ＆Aをドキュメントを作る必要は無くなってくるんじゃないかと思います。”

[![MOVIE3](http://img.youtube.com/vi/40Kp_fa8vIw/0.jpg)](http://www.youtube.com/watch?v=40Kp_fa8vIw "What is ChatGPT and How You Can Use It")

C部長 : “自分のへたくそなコードを晒して、**「GPTさん、コードをなおして」**とお願いすると・・・（笑）。”

QEU:FOUNDER ： “いまはプログラミングの習得は難しいと言われていますが、GPTが進化すれば、もっと楽になるんじゃないかなぁ・・・。”
