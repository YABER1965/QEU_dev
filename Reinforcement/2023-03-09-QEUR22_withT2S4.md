---
title: QEUR22_withT2S4:　閑話休題～Waifuは未知の世界へ
date: 2023-03-09
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "REWARD", "強化学習"]
excerpt: T法(2)をテクノメトリックスとして使った強化学習
---

## QEUR22_withT2S4:　閑話休題～Waifuは未知の世界へ

## ～　こんなモンを作って、いいのだろうか・・・　～

### ・・・　前回のつづきです（Stable_Diffusionの）　・・・

QEU:FOUNDER ： “なんかパッとしないなぁ・・・。ちょっと違うタイプのを出してみたいです。”

C部長 : “じゃあ、コレをドン・・・。”

![imageJRL2-5-1](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-1.jpg)

QEU:FOUNDER ： “ここでむさくるしいおっさんを出しても、もっとパッとせんわ・・・。”

C部長 : “ちなみに各1枚しか画像を出力してませんからね。他にも、**使っているモデルにも問題がある**かもしれません。”

![imageJRL2-5-2](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-2.jpg)

C部長 : “ああ、これでもこのレベルか・・・。これは、「かたい」タイプのモデルです。写実的な描画が得意だが、イラストやアニメ系はいまいちですよ。”

![imageJRL2-5-3](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-3.jpg)

QEU:FOUNDER(設定年齢65歳) ： “・・・、ちょっとアニメ系が欲しいの・・・。”

C部長 (設定年齢50歳台初頭) : “FOUNDERが使っている操作画面は、**AUTOMATIC1111という、この業界(?)では有名なWeb-UI**ですね。ボクは、最近お宅のA君（係長）から**Python言語で出す方法**を教わりました。それでやってみましょう。”

![imageJRL2-5-4](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-4.jpg)

QEU:FOUNDER ： “おおっ、こんな感じでお願いします。”

C部長 ： “実は、使用するモデルを少しだけ変えたんです。少しだけイラスト類のデータも入っているヤツに・・・。”

```python
# -----
import torch
from torch import autocast
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler
import ipywidgets as widgets
from ipywidgets import interact

#%cd ~/../notebooks

## Use the lists below to select our model type, image output resolution, and the computer number format for inference
device = 'cuda'
## We recommend either v1-5 (index 1) or v2 (index 2)
model_id = ['CompVis/stable-diffusion-v1-4',"../datasets/stable-diffusion-diffusers/stable-diffusion-v1-5/",'../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/']
## We strongly recommend using the v1-5 and v1-4 models with size 512, and the v2 models with size 768.
size = [512, 768]
dtype = [torch.float16, torch.float32]

# Set your values here - defaults are for v2, size 768 x 768 with FP16 computer number format
model_ = model_id[0]
size_ = size[0] 
precision = dtype[0]

# -----
# Depending on the selections made above, the type of model loaded will change using this short if/else statement
print(f'Now loading Stable Diffusion {model_} model ({precision})...')
scheduler = EulerDiscreteScheduler.from_pretrained('stabilityai/stable-diffusion-2', subfold-er="scheduler")
if precision == torch.float16:
    if model_ == '../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/':
        pipe = StableDiffusionPipeline.from_pretrained(model_, torch_dtype=torch.float16, revision="fp16", scheduler = scheduler)
        pipe = pipe.to(device)
    else:
        pipe = StableDiffusionPipeline.from_pretrained(model_, torch_dtype=torch.float16, revision="fp16")
        pipe = pipe.to(device)
else:
    if model_ == '../datasets/stable-diffusion-diffusers-v2/stable-diffusion-2/':
        pipe = StableDiffusionPipeline.from_pretrained(model_, scheduler = scheduler)
        pipe = pipe.to(device)
    else:
        pipe = StableDiffusionPipeline.from_pretrained(model_)
        pipe = pipe.to(device)
print('Model now loaded. Head to next cell to generate images.')

# -----
sample_num = 5
lst = []

print(f'Generating samples from Stable Diffusion {model_} checkpoint ({precision})')

prompt = '(1girl:1.4),(dark:1.4),(moonlight:1.3),high quality,masterpiece,blue eye,twintail,green hair,realistic'
for j in range(sample_num):
    a = pipe(prompt,
             guidance_scale=9.0,
             height = size_,
             width = size_,
             num_inference_steps=30)['images'][0]
    lst.append(a)
    display(a)
    fig_name = './outputs/gen-image-D{}.png'.format(j)
    print("{} is done".format(fig_name))
    a.save(fig_name)

```

**(pic1)**

![imageJRL2-5-5](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-5.jpg)

**(pic2)**

![imageJRL2-5-6](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-6.jpg)

**(pic3)**

![imageJRL2-5-7](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-7.jpg)

QEU:FOUNDER ： “かなり、ワシの好みに近づいてきたよ・・・（笑）。”

C部長 ： “（ひでえ趣味だな）・・・。じゃあ、お好みの路線を追求しますよ！**プロンプトに「スタジオ・ジ〇リ」をいれました。**これでどうですか！”

```python
# -----
sample_num = 5
lst = []

print(f'Generating samples from Stable Diffusion {model_} checkpoint ({precision})')

prompt = '(1girl:1.4),(cute:1.4),(dark:1.1),(moonlight:1.1),high quality,masterpiece,blue eye,twintail,green hair,Studio Ghibli'
for j in range(sample_num):
    a = pipe(prompt,
             guidance_scale=9.0,
             height = size_,
             width = size_,
             num_inference_steps=30)['images'][0]
    lst.append(a)
    display(a)
    fig_name = './outputs/gen-image-Waifu{}.png'.format(j)
    print("{} is done".format(fig_name))
    a.save(fig_name)

```

**(pic1)**

![imageJRL2-5-8](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-8.jpg)

**(pic2)**

![imageJRL2-5-9](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-9.jpg)

**(pic3)**

![imageJRL2-5-10](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-10.jpg)

QEU:FOUNDER ： “う～ん、かなりアニメの雰囲気が出てきました。ただし、「あの巨匠」の作品かというと、ちょっと違うと思うが、その雰囲気はでています。悪くはない・・・。”

C部長 ： “これは、**「Waifu」という有名なモデル**を使っています。ここで入力するプロンプトの内容をまた変えて、**「違う会社の画風」**にしますよ。さらに猫ちゃんもつけました。”


```python
# -----
sample_num = 5
lst = []

print(f'Generating samples from Stable Diffusion {model_} checkpoint ({precision})')

prompt = '(1girl:1.4),(cat:1.4),(mountain:1.1),(standing:1.1),high quality,masterpiece,blue eye,twintail,green hair,(By Toei Animation:1.3)'
for j in range(sample_num):
    a = pipe(prompt,
             guidance_scale=9.0,
             height = size_,
             width = size_,
             num_inference_steps=30)['images'][0]
    lst.append(a)
    display(a)
    fig_name = './outputs/gen-image-Waifu{}.png'.format(j)
    print("{} is done".format(fig_name))
    a.save(fig_name)
```

**(pic1)**

![imageJRL2-5-11](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-11.jpg)

**(pic2)**

![imageJRL2-5-12](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-12.jpg)

**(pic3)**

![imageJRL2-5-13](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-13.jpg)

QEU:FOUNDER ： “まあ、ある意味、「今風の普通のアニメ絵」になったね。しかし、女の子に耳やしっぽがつくんだ（笑）。”

C部長 ： “**このAIのこういう「創造性」は、この手法のいい点でもあり、悪い点でもあります**ね。・・・で、FOUNDER・・・。どうですか？Stable_Diffusionの威力は・・・。”

QEU:FOUNDER ： “いままでは**「AIが奪う（であろう）仕事」**はデータ分析系のモノが多いと言われていました。これでは、**近い将来には「芸術系」の仕事の方が酷い**かもしれない。”

![imageJRL2-5-14](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-14.jpg)

QEU:FOUNDER ： “・・・でも、ちょっとホッとするのは小生が（出力したいと）思った画像が簡単には出てこないですね。”

C部長 ： “そりゃそうですよ。現在のところ、このAIは1人の自画像（ポートレート）を描くのは得意ですが、2人、3人と人物を増やすと難しくなります。さらに、手とか足先など繊細な部分がうまく描けないことが多いですよ。だからA君（オタクかつPC通）は、最近ではWeb-UI(AUTOMATIC1111)での出力をやめて、かわりに**Python言語で画像を出力させている**んです。Python言語で自分でプログラムを作れば、画像を細かく調整できると思って・・・。”

QEU:FOUNDER ： “小生のレベルは、まだそこまで行っていません。Web-UIでしばらく遊ばさせてもらいます。遊べる機能やパラメータもまだありますし・・・。”

C部長 ： “そこらへんのところ。順次、情報を共有していきましょう。”



## ～　まとめ　～

QEU:FOUNDER ： “この前の議論でピンと来た・・・。少子化って、つまるところ**「確率分布の問題」**なんだね。”

C部長 : “はぁ？確率分布？”

[![MOVIE1](http://img.youtube.com/vi/ogt5AMj62yk/0.jpg)](http://www.youtube.com/watch?v=ogt5AMj62yk "○The News ● 失敗続きのコロナ・経済対策　迫る“カタストロフ”に私たちはどう向き合うか【金子勝、児玉龍彦、望月衣塑子、尾形聡彦】")

C部長  ： “この前のカタストロフの議論ですか？”

![imageJRL2-5-15](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-15.jpg)

QEU:FOUNDER ： “さらに、こうも言っています。”

![imageJRL2-5-16](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-16.jpg)

C部長 : “あ～あ、いっちゃった・・・。”

![imageJRL2-5-17](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-17.jpg)

QEU:FOUNDER ： “正規分布は人為的な分布で、**自分の望むモノを発生させることが目的**です。でも、外部の自然の確率分布は絶えず動いており、たまにカタストロフが起こることがあります。例えば、昔は正規分布と自然の確率分布が同じく重なっていたとしても・・・。”

C部長 : “自然の確率分布が時間とともにシフトし、**2つの円が重なる面積がどんどん小さくなっていきます**。”

QEU:FOUNDER ： “それが、いわゆる少子化・・・。”

C部長  ： “正規分布側がパラメタ（目標と分散）を調整して適応すればいいんですけどね・・・。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

QEU:FOUNDER ： “しないんだ、これが・・・。”

![imageJRL2-5-18](/2023-03-09-QEUR22_withT2S4/imageJRL2-5-18.jpg)

QEU:FOUNDER ： “**保守って、英語ではMAINTAIN（維持すること）であるはず**なのだが・・・。”

C部長  ： “保守派は、100年前のパラメータを維持したいだけの、**ひたすら頑固な人の集まり**になっちゃった・・・。”


