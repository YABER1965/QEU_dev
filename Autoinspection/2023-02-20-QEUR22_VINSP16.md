---
title: QEUR22_VINSP16: 　SVMを使った分類系「教師あり学習」
date: 2023-02-20
tags: ["QEUシステム", "メトリックス", "Julia言語", "SOART", "外観検査", "機械学習"]
excerpt: julia言語とテクノメトリックスを使った外観検査自動機
---

## QEUR22_VINSP16: 　SVMを使った分類系「教師あり学習」

## ～　イケてる！　～

### ・・・　前回のつづきです　・・・

D先生 ： “あともう一歩なんだけどなぁ・・・。あとは両目RTメトリックスのBETA系のメトリックス群も取り入れてマハラノビス距離を取るとか・・・。“

**(61X10)**

![image3-17-1](/2023-02-18-QEUR22_VINSP14/image3-17-1.jpg)

**（61X05）**

![image3-17-2](/2023-02-18-QEUR22_VINSP14/image3-17-2.jpg)

**（31X10）**

![image3-17-3](/2023-02-18-QEUR22_VINSP14/image3-17-3.jpg)

**（31X05）**

![image3-17-4](/2023-02-18-QEUR22_VINSP14/image3-17-4.jpg)

QEU:FOUNDER ： “D先生・・・。ちょっと頭を冷やしてヒートマップ(↑)を見てください。もうすでに**「かなりイケている」**でしょ？画像はかなりよく、むしろ問題は**「マハラノビス距離そのもの」**だと思います。AREA-B(↑)において15種類のピンがあります。これをたった1つの分散共分散逆行列で正しく予測するのは難しいって・・・。それが現実に出てきたのが、「3番PINはうまく予測できるが、6番PINはダメダメ」という事象です。”

![image3-17-5](/2023-02-18-QEUR22_VINSP14/image3-17-5.jpg)

D先生 ： “・・・ということは？“

QEU:FOUNDER ： “次は**ベースライン**でSVM（サポートベクトルマシン）をやるね・・・。ディープラーニングはパラメタが多すぎるので簡単なサポートベクトルマシンで評価しておくと、その後で楽になります。”

D先生 ： “SVMではカーネルを変更できるので、判別能力との関係を調べておきたいですね。 “

![image3-17-6](/2023-02-18-QEUR22_VINSP14/image3-17-6.jpg)

QEU:FOUNDER ： “もう、我々も何回もSVMをやってきたので以降は説明はなし。それではプログラムをドン・・・。”

```python
# SVM for SOART metrics example
import pandas as pd
import math
import numpy as np
# Prediction
from sklearn import metrics, preprocessing
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix

# ----
# データを読み込む
# ----
# train
filepath_train = 'soart_mtxout_train.csv'
df_org_train = pd.read_csv(filepath_train)

# test
filepath_test  = 'soart_mtxout_test.csv'
df_org_test  = pd.read_csv(filepath_test)

# ----
# 異常分類の当てはめをやりなおし
# ----
# 欠陥分類を修理(OK.etc.)に変換する
def repair_defectlist(df_org):
    arr_jCol    = df_org.loc[:,"jCol"].values
    arr_defect  = df_org.loc[:,"defect"].values
    for i in range(len(arr_defect)):
        if   arr_jCol[i] == 4.0 and arr_defect[i] == "61X10":
            arr_defect[i] = "OK"
        elif arr_jCol[i] == 4.0 and arr_defect[i] == "61D05":
            arr_defect[i] = "OK"
        elif arr_jCol[i] == 7.0 and arr_defect[i] == "31X10":
            arr_defect[i] = "OK"
        elif arr_jCol[i] == 7.0 and arr_defect[i] == "31D05":
            arr_defect[i] = "OK"
    df_org.loc[:,"defect"] = arr_defect
    return df_org

# ----
# DeltaをDropする
# ----
# train
df_org_train = df_org_train.drop(labels=['iPic', 'icount', 'iRow', 'area', 'delta1', 'delta2', 'delta3', 'delta4', 'delta5', 'delta6'], axis=1)
# 異常分類の当てはめをやりなおし
df_org_train = repair_defectlist(df_org_train)

# test
df_org_test  = df_org_test.drop(labels=['iPic', 'icount', 'iRow', 'area', 'delta1', 'delta2', 'delta3', 'delta4', 'delta5', 'delta6'], axis=1)
# 異常分類の当てはめをやりなおし
df_org_test  = repair_defectlist(df_org_test)
```

![image3-17-7](/2023-02-18-QEUR22_VINSP14/image3-17-7.jpg)

```python
# ----
# 欠陥分類を数字(0,1,2)に変換する
def create_numberlist(arr_defect, list_defect, list_number):
    arr_result = []
    for i in range(len(arr_defect)):
        for j, jStr in enumerate(list_defect):
            if arr_defect[i] == jStr:
                arr_result.append(list_number[j])
    return arr_result

# ----
# Resultコラムを作成する 
# ----
# train
list_train_defect = ['OK', 'new', 'old', '31D05','31X10','61D05','61X10',]
list_train_number = [   0,     0,     0,      1 ,      2,      1,      2,]
arr_defect_train  = df_org_train.loc[:,"defect"].values
arr_result_train  = create_numberlist(arr_defect_train, list_train_defect, list_train_number)
print(arr_result_train)

# test(jCol = 4)
list_test_defect  = ['OK', '31D05','31X10','61D05','61X10',]
list_test_number  = [    0,      1,      2,      1,      2,]
df_test_jCol4     = df_org_test[df_org_test["jCol"]==4.0]
arr_defect_jCol4  = df_test_jCol4.loc[:,"defect"].values
arr_result_jCol4  = create_numberlist(arr_defect_jCol4, list_test_defect, list_test_number)
print(arr_result_jCol4)

# test(jCol = 7)
#arr_test_defect   = ['OK', '31D05','31X10','61D05','61X10',]
df_test_jCol7     = df_org_test[df_org_test["jCol"]==7.0]
arr_defect_jCol7  = df_test_jCol7.loc[:,"defect"].values
arr_result_jCol7  = create_numberlist(arr_defect_jCol7, list_test_defect, list_test_number)
print(arr_result_jCol7)

# X and y dataset into train and test dataset
X_train = df_org_train.loc[:, "jCol":"distance6"].values
y_train = arr_result_train
X_test_jCol4 = df_test_jCol4.loc[:, "jCol":"distance6"].values
y_test_jCol4 = arr_result_jCol4
X_test_jCol7 = df_test_jCol7.loc[:, "jCol":"distance6"].values
y_test_jCol7 = arr_result_jCol7

# ----
# パフォーマンス計測
def performance_model(model, X_test, y_test):
    # predict
    y_pred = model.predict(X_test)

    # accuracy
    print("accuracy:", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), "\n")
    # cm
    print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))
                
# SVM学習の実行
kernel_names= ['linear','rbf','poly','sigmoid']
for kernel_name in kernel_names:

    # linear model
    model = SVC(kernel=kernel_name)
    model.fit(X_train, y_train)

    # jCol = 4.0
    print("---- {}-{} ----\n".format("jCol=4", kernel_name))
    performance_model(model, X_test_jCol4, y_test_jCol4)

    # jCol = 7.0
    print("---- {}-{} ----\n".format("jCol=7", kernel_name))
    performance_model(model, X_test_jCol7, y_test_jCol7)

```

D先生 ： “結果が出てきましたが、これは驚きました。やっぱり(SVMによる)教師あり学習はイケていますね。”

---- jCol=4-linear ----
accuracy: 0.836 
[[148   0   2]
 [  8  42   0]
 [ 31   0  19]]
---- jCol=7-linear ----
accuracy: 0.636 
[[149   1   0]
 [ 40  10   0]
 [ 50   0   0]]

QEU:FOUNDER ： “いきなり**判別精度が80％を超える**とは思いませんでした。”

D先生 ： “問題は**端子傾き**の異常検出力が不足していることですね。 “

QEU:FOUNDER ： “この問題についても、ヒートマップを見てすでにわかっていることです。これは、いまだに情報不足であると考えていいじゃないでしょうか・・・。”

---- jCol=4-rbf ----
accuracy: 0.7 
[[150   0   0]
 [ 38  12   0]
 [ 37   0  13]]
---- jCol=7-rbf ----
accuracy: 0.6 
[[150   0   0]
 [ 50   0   0]
 [ 50   0   0]]
---- jCol=4-poly ----
accuracy: 0.652 
[[150   0   0]
 [ 50   0   0]
 [ 37   0  13]]
---- jCol=7-poly ----
accuracy: 0.624 
[[150   0   0]
 [ 44   6   0]
 [ 50   0   0]]
---- jCol=4-sigmoid ----
accuracy: 0.6 
[[150   0   0]
 [ 50   0   0]
 [ 50   0   0]]
---- jCol=7-sigmoid ----
accuracy: 0.6 
[[150   0   0]
 [ 50   0   0]
 [ 50   0   0]]

D先生 ： “カーネルはLinear以外のパフォーマンスは全然ダメですね。 “

QEU:FOUNDER ： “つまり、SOARTメトリックスの適用により**判別関数が簡単になっている**んですよ。”

![image3-17-8](/2023-02-18-QEUR22_VINSP14/image3-17-8.jpg)

D先生 ： “BETA系メトリックスを追加しましょうか。差分画像を見ても明らかな効果があります。“

![image3-17-9](/2023-02-18-QEUR22_VINSP14/image3-17-9.jpg)

QEU:FOUNDER ： “でもね、61X10のBETA画像ではあまり良い結果ではないんですよね。ただし、ここら辺の問題はカメラのセッティングの問題であって、計算スキームのせいにはできないでしょうね。・・・なにはともあれ、次はBETA画像を追加してSVM学習をしてみましょう。”


## ～　まとめ　～

### ・・・　前回のつづきです　・・・

QEU:FOUNDER ： “「だれかさん」が地域政党を立ち上げるというのは**「かわいそう、けしからん、反知性主義」**がモットーのイケメンにとってはかえって「福音」だと思うよ。ちなみに、反知性主義というのは今回の場合には反エリート、エスタブリッシュメント（特権階級）と読んでください。”

![image3-17-10](/2023-02-18-QEUR22_VINSP14/image3-17-10.jpg)

C部長 : “この理屈はわかるかなぁ・・・。ちなみに、FOUNDERが彼（↑）の立場であれば、スローガンをどう打ち上げますか？”

QEU:FOUNDER ： “小生は過激ですよ。**「①沖縄遷都、②風力エネルギー重視への大転換、③高齢者によるイノベーション」**だから・・・。”

C部長 : “うわっ・・・。過激・・・。でも、①と②はわかりますが、なんで③がいきなり出てくるんですか？”

QEU:FOUNDER ： “最近はコメントはしていませんが、この番組は「高齢者によるイノベーション」です（笑）。”

### 項目 – メリット（対ＧＤＰ比） – スパン
### 沖縄遷都 → 20%up　→ 10年スパン
### 風力エネルギー重視への大転換 → 10%up　→ 30年スパン
### 高齢者によるイノベーション→ 10%up　→ 5年スパン

C部長 : “「高齢者によるイノベーション」って、たった5年スパンなの？”

QEU:FOUNDER ： “これは、**ＡＩの特性とＱＥＵシステムのコンセプトにかかわる話**になるから、改めて話をしましょう。”
